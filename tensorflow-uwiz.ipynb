{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2cf830ea6d6b778",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a573bc08af0efb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import uncertainty_wizard as uwiz\n",
    "import matplotlib.pyplot as plt\n",
    "from uncertainty_wizard.models.stochastic_utils.layers import UwizBernoulliDropout, UwizGaussianDropout, UwizGaussianNoise\n",
    "from uncertainty_wizard.models._stochastic._stochastic_mode import StochasticMode\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bdb8c3f863bb39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Load, Preprocess MNIST and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9ab9d10768a86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load mnist data \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = (x_train.astype('float32') / 255).reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = (x_test.astype('float32') / 255).reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "model = uwiz.models.StochasticSequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(UwizBernoulliDropout(0.5, stochastic_mode=StochasticMode()))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.legacy.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=32,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n",
    "\n",
    "# Save the model\n",
    "model.inner.save_weights('mnist_model_stochastic.h5')\n",
    "print(\"Model (mnist_model_stochastic) saved to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070ad9c",
   "metadata": {},
   "source": [
    "## 3. Plot Traning & Validation Accuracy and Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde9074a47b1f01",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206280fcffe7299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the saved model weights\n",
    "model.inner.load_weights('mnist_model_stochastic.h5')\n",
    "print(\"Model (mnist_model_stochastic) loaded from disk\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy', test_acc)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "num_samples = 25\n",
    "predictions = model.predict(x_test[:num_samples])\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcd005",
   "metadata": {},
   "source": [
    "## 5. Plot Predictions & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'True: {y_true[i]}, Predicted: {predicted_labels[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues',\n",
    "            xticklabels=[str(i) for i in range(10)],\n",
    "            yticklabels=[str(i) for i in range(10)])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b725c7e1d3e66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6. Analyze the Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dce07d4d720e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the saved model weights \n",
    "model.inner.load_weights('mnist_model_stochastic.h5')\n",
    "print(\"Model (mnist_model_stochastic) loaded from disk\")\n",
    "\n",
    "# Perform uncertainty quantification\n",
    "quantifiers = ['pcs', 'mean_softmax']\n",
    "results = model.predict_quantified(x_test,\n",
    "                                    quantifier=quantifiers,\n",
    "                                    batch_size=64,\n",
    "                                    sample_size=32,\n",
    "                                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0bf8a51eadd8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7. Plots for Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the uncertainty distribution\n",
    "uncertainty_scores = results[1][1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(uncertainty_scores, bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Uncertainty Scores')\n",
    "plt.xlabel('Uncertainty Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot the predictive confidence score\n",
    "confidence_scores = results[1][0]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(confidence_scores, bins=50, alpha=0.7, color='green')\n",
    "plt.title('Distribution of Predictive Confidence Scores')\n",
    "plt.xlabel('Predictive Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot the predictive confidence score vs uncertainty score\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(confidence_scores, uncertainty_scores, alpha=0.5, color='red')\n",
    "plt.title('Predictive Confidence Score vs Uncertainty Score')\n",
    "plt.xlabel('Predictive Confidence Score')\n",
    "plt.ylabel('Uncertainty Score')\n",
    "plt.show()\n",
    "\n",
    "# Plot PCS and Mean Softmax scores for a subset of the test set data  \n",
    "#qualitative, visual correlation between each image and its corresponding scores.\n",
    "num_samples = 25\n",
    "pcs_scores, mean_softmax_scores = results[0][1], results[1][1]\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'PCS: {pcs_scores[i]:.2f}\\nMean Softmax: {mean_softmax_scores[i]:.2f}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot distribution of PCS and Mean Softmax scores\n",
    "pcs_scores = results[0][1]\n",
    "mean_softmax_scores = results[1][1]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(pcs_scores, bins=50, alpha=0.7)\n",
    "plt.xlabel('PCS Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of PCS Scores')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mean_softmax_scores, bins=50, alpha=0.7)\n",
    "plt.xlabel('Mean Softmax Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Softmax Scores')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bar Chart Style:\n",
    "This function plots bar charts for Prediction Confidence Score (PCS) and Mean Softmax Score for a subset of samples.\n",
    "It uses two subplots:\n",
    "The first subplot (plt.subplot(1, 2, 1)) displays a bar chart for PCS scores.\n",
    "The second subplot (plt.subplot(1, 2, 2)) shows a bar chart for Mean Softmax scores.\n",
    "Each bar represents a single sample, and the height of the bar indicates the score.\n",
    "This style is useful for quickly assessing the distribution and range of scores across multiple samples.\n",
    "\n",
    "\n",
    " for a quantitative overview of the scores across multiple samples\n",
    " \n",
    "In a technical or research context, I would lean towards the first method due to its clear, quantitative presentation. However, for educational purposes, presentations, or to quickly grasp how scores relate to actual data, the second method is more illustrative and engaging."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9c12b516787af99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pcs_scores = results[0][1][:num_samples]  # Adjust indices based on your results structure\n",
    "mean_softmax_scores = results[1][1][:num_samples]\n",
    "\n",
    "# Plot PCS scores\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(num_samples), pcs_scores)\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('PCS Score')\n",
    "plt.title('PCS Scores for Test Samples')\n",
    "\n",
    "# Plot Mean Softmax scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(num_samples), mean_softmax_scores)\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Mean Softmax Score')\n",
    "plt.title('Mean Softmax Scores for Test Samples')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a59a83521f2d6149",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
