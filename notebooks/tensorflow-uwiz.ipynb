{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf616ac946441311",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a573bc08af0efb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, Mean\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import uncertainty_wizard as uwiz\n",
    "import matplotlib.pyplot as plt\n",
    "from uncertainty_wizard.models.stochastic_utils.layers import UwizBernoulliDropout, UwizGaussianDropout, UwizGaussianNoise\n",
    "from uncertainty_wizard.models._stochastic._stochastic_mode import StochasticMode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d5a2fba7f1695",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af4e221598c486",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f'Number og GPUs Available: {len(gpus)}')\n",
    "    for gpu in gpus:\n",
    "        print('Name:', gpu.name, 'Type:', gpu.device_type)\n",
    "else:\n",
    "    print('No GPUs found. Please check your TensorFlow installation and GPU setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bdb8c3f863bb39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Load and preprocess MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf9ab9d10768a86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load mnist data \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Lenght of training samples\n",
    "print('Lenght of training samples: ', len(x_train))\n",
    "\n",
    "# Lenght of test samples\n",
    "print('\\nLenght of test samples: ', len(x_test))\n",
    "\n",
    "# Shape \n",
    "print('\\nShape: ', x_train[0].shape)\n",
    "print('\\n-----------------------------------------------------------------')\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = (x_train.astype('float32') / 255).reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = (x_test.astype('float32') / 255).reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "\n",
    "def create_stochastic_model():\n",
    "    model = uwiz.models.StochasticSequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(UwizBernoulliDropout(0.5, stochastic_mode=StochasticMode()))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                  optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# plot 4 images as gray scale\n",
    "#plt.subplot(141)\n",
    "#plt.imshow(x_train[0])\n",
    "#plt.subplot(142)\n",
    "#plt.imshow(x_train[1])\n",
    "#plt.subplot(143)\n",
    "#plt.imshow(x_train[2])\n",
    "#plt.subplot(144)\n",
    "#plt.imshow(x_train[3])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize Filters "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5ecb77cf89ba163"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def visualize_filters_and_layers(model, max_filters=6, layers_to_visualize=None):\n",
    "    # Access the inner Keras model\n",
    "    keras_model = model.inner\n",
    "    \n",
    "    if layers_to_visualize is None:\n",
    "        layers_to_visualize = [0]\n",
    "        \n",
    "    for layer_index in layers_to_visualize:\n",
    "        layer = keras_model.layers[layer_index]\n",
    "        if not isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            print(\"The first layer is not a Conv2D layer. Please adjust the layer index.\")\n",
    "            return\n",
    "    \n",
    "    # Get the filters from the layer\n",
    "    filters, biases = layer.get_weights()\n",
    "    # Normalize the filters\n",
    "    f_min, f_max = filters.min(), filters.max()\n",
    "    filters = (filters - f_min) / (f_max - f_min)\n",
    "    # Plot the first few filters\n",
    "    n_filters = min(max_filters, filters.shape[3])\n",
    "    \n",
    "    n_columns = 6\n",
    "    n_rows = n_filters // n_columns if n_filters % n_columns == 0 else n_filters // n_columns +1\n",
    "    plt.figure(figsize=(20, n_rows * 3))\n",
    "    plt.suptitle(f'Filters from layer index {layer_index} - {layer.name}')\n",
    "    \n",
    "    for i in range(n_filters):\n",
    "        # Get the filter\n",
    "        f = filters[:, :, :, i]\n",
    "        # Plot each channel. Assuming your filters are in grayscale, modify to f.shape[2] if color\n",
    "        for j in range(f.shape[2]):\n",
    "            ax = plt.subplot(n_rows, n_columns, i + 2)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            plt.imshow(f[:, :, j], cmap='gray')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16f24c22f7fb485f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "visualize_filters_and_layers(model, max_filters=8, layers_to_visualize=[0, 1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f26a70294501bda",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a278135264fa83ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.inner.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7201f13398591a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "\n",
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "for i in range(num_images):\n",
    "    ax = fig.add_subplot(1, num_images, i+1)\n",
    "    ax.matshow(x_train[i].squeeze(), cmap='gray')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "fig2 = plt.figure(figsize=(10, 2.5))\n",
    "for i in range(num_images):\n",
    "    ax = fig2.add_subplot(1, num_images, i+1)\n",
    "    ax.matshow(x_test[i].squeeze(), cmap='gray')\n",
    "    \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3077fe67cc918969",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Train\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6af690cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3cb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_stochastic_model()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=2000,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "                               tf.keras.callbacks.TensorBoard(log_dir='data/logs', histogram_freq=1)])\n",
    "\n",
    "# Save the model\n",
    "os.makedirs(os.path.dirname('data/model/'), exist_ok=True)\n",
    "model.inner.save_weights('data/model/clean_model_weights.h5')\n",
    "print(\"\\nTraining completed, model weights saved\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def visualize_feature_maps(sequential_model, image):\n",
    "    keras_model = sequential_model.inner\n",
    "    layer_outputs = [layer.output for layer in keras_model.layers if isinstance(layer, tf.keras.layers.Conv2D)]\n",
    "    activation_model = tf.keras.models.Model(inputs=keras_model.input, outputs=layer_outputs)\n",
    "    # Get feature map activations\n",
    "    activations = activation_model.predict(image[np.newaxis, ...])\n",
    "    # Plot the feature maps of the first convolutional layer\n",
    "    first_layer_activations = activations[0]\n",
    "    n_features = first_layer_activations.shape[-1]\n",
    "    size = first_layer_activations.shape[1]\n",
    "    n_cols = n_features // 16 + min(n_features % 16, 1)\n",
    "    display_grid = np.zeros((size * n_cols, size * 16))\n",
    "    for col in range(n_cols):\n",
    "        for row in range(16):\n",
    "            if col * 16 + row >= n_features:\n",
    "                break\n",
    "            channel_image = first_layer_activations[0, :, :, col * 16 + row]\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title('Feature maps')\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e340f18824e9fde5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_to_visualize = x_test[0]  # Example image from your dataset\n",
    "visualize_feature_maps(model, image_to_visualize)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a99151ef62eee43",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc8fdaab66ec5ef7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Adversarial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a318e983f31f56",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Purpose of the adversarial training is to enhance the model's robustness by training it on both clean and adversarially perturbed data. The idea is to make the model learn to generalize well even under adversarial conditions. \n",
    "\n",
    " Process during adversarial training is that we generate adversarial examples using methods like **Projected Gradient Descent (PGD) and then train the model on these examples. Tis is meant to simulate potential attacks and teach the model to recognize and correctly classify both unaltered and altered inputs.\n",
    "\n",
    "The loss function in the adversarial training setup (CategoricalCrossentropy(from_logits=True)) expects logits (i.e., the model's raw output before the softmax layer) as inputs. If the model ends with a softmax layer, this could mislead the training process.\n",
    "\n",
    "Solution: Ensure that the model's output is compatible with the loss function's expectations. If the model ends with a softmax activation, we need to set from_logits=False or remove the softmax layer and handle the activation externally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13cddaf4d10733",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cleverhans tutorial\n",
    "\n",
    "#### Fast Gradient Sign Method (FGSM)\n",
    "\n",
    "FGSM is one of the simplest and fastest methods to generate adversarial examples. It perturbs each input by a small amount in the direction of the gradient of the loss with respect to the input.\n",
    "\n",
    "- `eps` (epsilon) parameter controls the magnitude of the perturbation added to the input images. It defines the step size in the direction of the loss gradient and essentially controls the strength of the attack. Smaller values of `eps` generate adversarial examples that are closer to the orginal inputs, while larger values of `eps` may result in more noticeable perturbations.\n",
    "- `clip_min`and `clip_max` parameters define the minimum and maximum values that any component of the input tensor can take. They are used to clip the adversarial images to ensure they remain valid images. For example, for images with pixel values in the range [0,1], you would set `clip_min=0` and `clip_max=1`.\n",
    "- `norm` parameter defines the norm of the perturbations. It's not directly used in FGSM in CleverHans but is relevant for methods that require specifying the norm type for perturbations (like PGD)\n",
    "\n",
    "#### Projected Gradient Descent (PGD)\n",
    "\n",
    "PGD is more powerful attack compared to FGSM, iterating multiple times to find more effective adversarial examples within a specified perturbation budget.\n",
    "\n",
    "**Parameters**:\n",
    "- `eps`; similar to FGSM, it controls the maximum perturbation that can be added to the input images. It defines the \"budget\" within which the adversarial examples can be crafted. \n",
    "- `eps_iter` controls the step size or the amount of perturbation introduced in each iteration of the attack. Smaller values make the attack more precise but they may require more iterations to converge.\n",
    "- `nb_iter` specifies the number of iterations the attack will run for. More iterations can lead to more effective adversarial examples but increase computation time.\n",
    "- `clip_min` and `clip_max` ensures the perturbated images are clipped to maintain valid image values, similar to FGSM.\n",
    "- `norm`; the norm of the perturbations to use. Common values include `np.inf` (L-infinity norm, withich means changing all pixels with the same magnitude), 1(L1 norm), and 2(L2 norm). The choice of norm affects the nature of the perturbations.\n",
    "\n",
    "\n",
    "For both FGSM and PGD, setting *eps, eps_iter* and *nb_iter* appropriately is crucial. These need to be chosen considering model's sensitivity and the desired strength and subtlety of the attack.\n",
    "\n",
    "\n",
    "**References**:\n",
    "[Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)\n",
    "[Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/abs/1706.06083)\n",
    "[CleverHans Github Repository](https://github.com/cleverhans-lab/cleverhans)\n",
    "[Adversarial Robustness - Theory and Practice](https://adversarial-ml-tutorial.org/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3d595b4a133ce",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-initialize the model for adversarial training\n",
    "adv_training_model = create_stochastic_model()\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "train_loss = Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 1000\n",
    "eps = 0.03\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch + 1}/{epochs}')\n",
    "    \n",
    "    # Initialize the progress bar\n",
    "    progbar = Progbar(target=len(x_train) // batch_size, unit_name='batch')\n",
    "    \n",
    "    train_loss.reset_state()\n",
    "    train_accuracy.reset_state()\n",
    "    \n",
    "    for batch_index, (x_batch, y_batch) in enumerate(tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate adversarial examples \n",
    "            x_batch_adv = projected_gradient_descent(adv_training_model.inner, x_batch, eps, 0.01, 40, np.inf)\n",
    "            \n",
    "            # Predict on adversarial examples\n",
    "            adv_pred = adv_training_model.inner(x_batch_adv, training=True)\n",
    "            loss = loss_object(y_batch, adv_pred)\n",
    "        \n",
    "        # Compute gradients and update model weights\n",
    "        gradients = tape.gradient(loss, adv_training_model.inner.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, adv_training_model.inner.trainable_variables))\n",
    "        \n",
    "        # Update the metrics\n",
    "        train_loss.update_state(loss)\n",
    "        train_accuracy.update_state(y_batch, adv_pred)\n",
    "        \n",
    "        # Update the progress bar\n",
    "        progbar.update(batch_index + 1, values=[(\"loss\", train_loss.result()),\n",
    "                                                (\"accuracy\", train_accuracy.result())])\n",
    "\n",
    "    # Logging the metrics at the end of an epoch\n",
    "    print(f'Epoch {epoch + 1}, Loss: {train_loss.result().numpy()}, Accuracy: {train_accuracy.result().numpy()}')\n",
    "        \n",
    "os.makedirs(os.path.dirname('data/model/'), exist_ok=True)\n",
    "adv_training_model.inner.save_weights('data/model/adv_trained_model_weights.h5')\n",
    "print(\"\\nAdversarial training completed, model weights saved\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070ad9c",
   "metadata": {},
   "source": [
    "## 4. Plot Traning & Validation Accuracy and Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde9074a47b1f01",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206280fcffe7299",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the saved model weights\n",
    "model.inner.load_weights('data/model/clean_model_weights.h5')\n",
    "print(\"Model weights loaded from disk\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "#print('\\nTest accuracy', test_acc)\n",
    "#print('\\nTest loss', test_loss)\n",
    "print(f'\\nTest Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}')\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = tf.reduce_mean(tf.square(y_pred - y_test))\n",
    "print(f'\\nMSE: {mse:.3f}')\n",
    "\n",
    "\n",
    "num_samples = 25\n",
    "predictions = model.predict(x_test[:num_samples])\n",
    "predicted_labels = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb29f409fddb49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6bd95fac83eaea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, rmse = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(f'Test RMSE: {round(rmse, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41bc5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_accuracy}\\nTest loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d831671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix and Classification Report\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred_classes))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_true, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff89f3ccc069b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Adversarial Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50605c8d22a5e829",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The adversarial evaluation phase is designed to assess how well the model can identify and correctly classify images that have been deliberately perturbated to mislead it. This phase does not directly evaluate the adversarial training but rather tests the model's robustness against adversarial attacks. \n",
    "\n",
    "To evaluate the model's performance and robustness after it has been trained, specifically its ability to withstand adversarial attacks. This phase assesses how well the model, whether trained traditionally or with adversarial examples, can handle new, unseen adversarial inputs.\n",
    "\n",
    "We generate new adversarial examples from the test set (which the model has not seen during training) using attack methods like **Fast Gradient Sign Method (FGSM) and PGD. The model's accuracy and loss metrics are then evaluated based on its predictions for these adversially perturbed images.\n",
    "\n",
    "Whether the model underwent adversarial training or not, the adversarial evaluation can be performed to test its robustness. The expectation is that models trained with adversarial examples will perform better in this phase than models trained only on clean data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5929ef4d13b0db",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1a46505b56c48",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generata adversarial examples batch by batch within a loop then trying to evaluate the model on a single batch of adversarial examples against the entire `y_test` dataset\n",
    "\"\"\"\n",
    "\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "test_accuracy = SparseCategoricalAccuracy()\n",
    "\n",
    "# Evaluate on clean examples\n",
    "for x_batch, y_batch in tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128):\n",
    "    predictions = model.predict(x_batch)\n",
    "    test_accuracy.update_state(y_batch, predictions)\n",
    "    \n",
    "accuracy_clean = test_accuracy.result().numpy() * 100\n",
    "print(f'\\nTest accuracy on clean examples: {accuracy_clean}')\n",
    "\n",
    "# Adversarial evaluation settings\n",
    "eps = 0.3\n",
    "test_accuracy_fgsm = SparseCategoricalAccuracy()\n",
    "test_accuracy_pgd = SparseCategoricalAccuracy()\n",
    "\n",
    "# Evaluate on adversarial examples (FGSM and PGD)\n",
    "for x_batch, y_batch in tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128):\n",
    "    # FGSM examples\n",
    "    x_adv_fgsm = fast_gradient_method(model.inner, x_batch, eps, np.inf)\n",
    "    predictions_fgsm = model.predict(x_adv_fgsm)\n",
    "    test_accuracy_fgsm.update_state(y_batch, predictions_fgsm)\n",
    "    \n",
    "        \n",
    "    # PGD examples\n",
    "    x_adv_pdg = projected_gradient_descent(model.inner, x_batch, eps, 0.01, 40, np.inf)\n",
    "    predictions_pdg = model.predict(x_adv_pdg)\n",
    "    test_accuracy_pgd.update_state(y_batch, predictions_pdg)\n",
    "    \n",
    "accuracy_fgsm = test_accuracy_fgsm.result().numpy() * 100\n",
    "accuracy_pdg = test_accuracy_pgd.result().numpy() * 100\n",
    "\n",
    "\n",
    "print(f'\\nTest accuracy on FGSM adversarial examples: {accuracy_fgsm}')\n",
    "print(f'Test accuracy on PDG adversarial examples: {accuracy_pdg}')\n",
    "\n",
    "accuracies = [accuracy_clean, accuracy_fgsm, accuracy_pdg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110c7353532af6a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating adversarial examples for the entire test dataset and then evaluating the model on these examples\n",
    "\"\"\"\n",
    "\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    \n",
    "model = create_stochastic_model()\n",
    "model.inner.load_weights('data/model/clean_model_weights.h5')\n",
    "\n",
    "# Generate adversarial examples for the entire test set\n",
    "x_test_adv_fgsm = fast_gradient_method(model.inner, x_test, eps, np.inf, clip_min=0., clip_max=1.)\n",
    "x_test_adv_pgd = projected_gradient_descent(model.inner, x_test, eps, eps_iter=0.01, nb_iter=40, norm=np.inf, clip_min=0., clip_max=1.)\n",
    "\n",
    "# Evaluate model on the entire set of FGSM adversarial examples\n",
    "loss_fgsm, accuracy_fgsm_entire = model.evaluate(x_test_adv_fgsm, tf.keras.utils.to_categorical(y_test), verbose=2)\n",
    "print(f'Accuracy on FGSM adversarial examples: {accuracy_fgsm_entire*100:.2f}%')\n",
    "\n",
    "# Evaluate the model on the entire set of PGD adversarial examples\n",
    "loss_pgd, accuracy_pgd_entire = model.evaluate(x_test_adv_pgd, tf.keras.utils.to_categorical(y_test), verbose=2)\n",
    "print(f'Accuracy on PGD adversarial examples: {accuracy_pgd_entire*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcd005",
   "metadata": {},
   "source": [
    "## 7. Plot Predictions, Confusion Matrix, Adversarial examples and Comparison between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487d977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f'True: {y_true[i]}, Predicted: {predicted_labels[i]}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues',\n",
    "            xticklabels=[str(i) for i in range(10)],\n",
    "            yticklabels=[str(i) for i in range(10)])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Classification Report\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "if y_true.ndim > 1:\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "else:\n",
    "    y_true_labels = y_true\n",
    "# Generate classification report\n",
    "report = classification_report(y_true_labels, y_pred_labels, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame\n",
    "df_report = pd.DataFrame(report).transpose()\n",
    "\n",
    "# Remove the 'support' \n",
    "df_report = df_report.drop(columns=['support'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_report, x=df_report.index, y='precision', label='Precision', color='b', alpha=0.6)\n",
    "sns.barplot(data=df_report, x=df_report.index, y='recall', label='Recall', color='g', alpha=0.6)\n",
    "sns.barplot(data=df_report, x=df_report.index, y='f1-score', label='F1-Score', color='r', alpha=0.6)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Classification Report')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Clean and Adversarial examples\n",
    "\n",
    "#x_adv_fgsm = fast_gradient_method(model.inner, x_test[:num_samples], eps, np.inf)\n",
    "#predictions_clean = np.argmax(model.predict(x_test[:num_samples]), axis=1)\n",
    "#predictions_adv = np.argmax(model.predict(x_adv_fgsm), axis=1)\n",
    "\n",
    "# Generate FGSM adversarial examples\n",
    "x_adv_fgsm = fast_gradient_method(model.inner, x_test[:num_samples], eps, np.inf)\n",
    "predictions_fgsm = np.argmax(model.predict(x_adv_fgsm), axis=1)\n",
    "\n",
    "# Generate PGD adversarial examples\n",
    "x_adv_pgd = projected_gradient_descent(model.inner, x_test[:num_samples], eps, 0.01, 40, np.inf)\n",
    "predictions_pgd = np.argmax(model.predict(x_adv_pgd), axis=1)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "#plt.figure(figsize=(2 * num_samples, 6))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Plot clean images\n",
    "        plt.subplot(3, num_samples, i + 1)\n",
    "        plt.imshow(x_test[i], cmap='gray')  # If x_test is not already in 28x28, reshape is needed\n",
    "        plt.title(f'Clean\\nPred: {np.argmax(model.predict(x_test[i:i+1]), axis=1)[0]}', fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot FGSM adversarial images\n",
    "        plt.subplot(3, num_samples, num_samples + i + 1)\n",
    "        plt.imshow(x_adv_fgsm[i], cmap='gray')\n",
    "        plt.title(f'FGSM\\nPred: {predictions_fgsm[i]}', fontsize=9)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot PGD adversarial images\n",
    "        plt.subplot(3, num_samples, 2 * num_samples + i + 1)\n",
    "        plt.imshow(x_adv_pgd[i], cmap='gray')\n",
    "        plt.title(f'PGD\\nPred: {predictions_pgd[i]}', fontsize=9)\n",
    "        plt.axis('off')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f'pred_clean_vs_adv_{timestamp}.png'\n",
    "plot_dir = './data/plots//evaluate'\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "plt.savefig(os.path.join(plot_dir, filename))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compare\n",
    "plt.figure(figsize=(8, 6))\n",
    "bar_positions = np.arange(len(accuracies))\n",
    "plt.bar(bar_positions, accuracies, color=['blue', 'green', 'red'])\n",
    "plt.xticks(bar_positions, labels=['Clean', 'FGSM', 'PGD'])\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy: Clean vs Adversarial Examples')\n",
    "plt.ylim(0, 110)\n",
    "\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 2, f'{acc:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b725c7e1d3e66",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 8. Analyze the Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271832004bd5a00",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the context of neural networks, uncertainty quantification is crucial for assessing the confidence of model predictions. There are two primary types of uncertainty:\n",
    "\n",
    "1. **Aleatoric Uncertainty**: This type of uncertainty is inherent in the data. It arises from noise or variability in the data and can be captured directly from the data itself.\n",
    "2. **Epistemic Uncertainty**: This uncertainty is due to the model's lack of knowledge. It can be reduced with more data or better models and is often where dropout-based methods come into play.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6dce07d4d720e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the saved model weights \n",
    "model.inner.load_weights('data/model/model_weights.h5')\n",
    "print(\"Model weights loaded from disk\")\n",
    "\n",
    "# Perform uncertainty quantification\n",
    "quantifiers = ['pcs', 'mean_softmax']\n",
    "results = model.predict_quantified(x_test,\n",
    "                                    quantifier=quantifiers,\n",
    "                                    batch_size=64,\n",
    "                                    sample_size=32,\n",
    "                                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0bf8a51eadd8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 9. Plots for Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b0ba544820655",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. **Prediction Confidence Score (PCS):**\n",
    "    \n",
    "    - PCS is a measure of the model's confidence in its predictions. For classification tasks, this often translates to how high the softmax output is for the predicted class. A higher PCS indicates higher confidence in the prediction.\n",
    "2. **Mean Softmax:**\n",
    "    \n",
    "    - Mean Softmax is typically used in stochastic models where multiple predictions are made for the same input (as in Monte Carlo Dropout). It refers to the average of the softmax outputs across all predictions for a given input. It can be interpreted as an averaged confidence level across multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b2ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the uncertainty distribution\n",
    "uncertainty_scores = results[1][1]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(uncertainty_scores, bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Distribution of Uncertainty Scores')\n",
    "plt.xlabel('Uncertainty Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot distribution of PCS and Mean Softmax scores\n",
    "plt.figure(figsize=(10,10))\n",
    "pcs_scores = results[0][1]\n",
    "mean_softmax_scores = results[1][1]\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(pcs_scores, bins=50, alpha=0.7)\n",
    "plt.xlabel('PCS Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of PCS Scores')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(mean_softmax_scores, bins=50, alpha=0.7)\n",
    "plt.xlabel('Mean Softmax Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Softmax Scores')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a83521f2d6149",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcs_scores = results[0][1][:num_samples]  \n",
    "mean_softmax_scores = results[1][1][:num_samples]\n",
    "\n",
    "# Plot PCS scores\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(num_samples), pcs_scores)\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('PCS Score')\n",
    "plt.title('PCS Scores for Test Samples')\n",
    "\n",
    "# Plot Mean Softmax scores\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(num_samples), mean_softmax_scores)\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Mean Softmax Score')\n",
    "plt.title('Mean Softmax Scores for Test Samples')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5dafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "plt.figure(figsize=(10, 10))\n",
    "pcs_predictions = results[0][0]\n",
    "pcs_confidences = results[0][1]\n",
    "mean_softmax_predictions = results[1][0]\n",
    "mean_softmax_confidences = results[1][1]\n",
    "\n",
    "\n",
    "plt.hist(pcs_confidences, bins=50, alpha=0.7, color='blue', label='PCS')\n",
    "plt.hist(mean_softmax_confidences, bins=50, alpha=0.7, color='green', label='Mean Softmax')\n",
    "plt.title('Distribution of Predictive Confidence Scores')\n",
    "plt.xlabel('Predictive Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
